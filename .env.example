# Probabilistic U-Net Configuration Template
# Copy this file to .env and fill in your values
# IMPORTANT: Never commit .env to version control!

# =============================================================================
# DATASET CONFIGURATION
# =============================================================================

# Dataset paths and settings
DATASET_ROOT_DIR=./datasets/Cityscapes
DATASET_IMG_SIZE=512,1024

# Dataset splits
DATASET_TRAIN_SPLIT=train
DATASET_VAL_SPLIT=val
DATASET_TEST_SPLIT=test

# Augmentation settings
DATASET_USE_AUGMENTATION=true
DATASET_AUGMENTATION_SEED=200

# DataLoader settings
DATASET_BATCH_SIZE=4
DATASET_NUM_WORKERS=4
DATASET_SHUFFLE_TRAIN=true
DATASET_SHUFFLE_VAL=false
DATASET_DROP_LAST=true
DATASET_DEVICE=cuda

# Cityscapes-specific settings
DATASET_MODE=fine
DATASET_TARGET_TYPE=semantic

# =============================================================================
# TRAINING CONFIGURATION
# =============================================================================

# Model architecture
MODEL_LATENT_DIM=6
MODEL_BETA=5.0
MODEL_NUM_SAMPLES=16
MODEL_USE_POSTERIOR=true

# Training hyperparameters
TRAINING_EPOCHS=100
TRAINING_LEARNING_RATE=0.0001
TRAINING_WEIGHT_DECAY=0.00001
TRAINING_BATCH_SIZE=4
TRAINING_ACCUMULATE_GRAD_BATCHES=1

# Optimization
TRAINING_OPTIMIZER=adamw
TRAINING_LR_SCHEDULER=cosine
TRAINING_WARMUP_EPOCHS=5
TRAINING_MIN_LR=0.000001

# Regularization
TRAINING_GRADIENT_CLIP_VAL=1.0
TRAINING_LABEL_SMOOTHING=0.1

# Validation
TRAINING_VAL_EVERY_N_EPOCH=1
TRAINING_CHECK_VAL_EVERY_N_EPOCH=1

# Checkpointing
TRAINING_SAVE_TOP_K=3
TRAINING_MONITOR_METRIC=val/mIoU
TRAINING_MONITOR_MODE=max

# Early stopping
TRAINING_EARLY_STOP_PATIENCE=20
TRAINING_EARLY_STOP_MIN_DELTA=0.001

# WandB logging (fill in your values)
WANDB_PROJECT=Probabilistic-UNet
WANDB_ENTITY=your-wandb-entity
WANDB_RUN_NAME=experiment_001
TRAINING_LOG_EVERY_N_STEPS=10

# System
TRAINING_NUM_WORKERS=4
TRAINING_SEED=42
TRAINING_PRECISION=16-mixed
TRAINING_ACCELERATOR=auto
TRAINING_DEVICES=1

# Paths
TRAINING_CHECKPOINT_DIR=./checkpoints
TRAINING_LOG_DIR=./logs

# Resume training (leave empty if starting fresh, or provide checkpoint path)
TRAINING_RESUME_FROM_CHECKPOINT=
