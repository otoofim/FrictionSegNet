{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "642d4bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 08:08:24.720651: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "from IPython.display import Image \n",
    "import cv2\n",
    "from tempfile import TemporaryFile\n",
    "from scipy import stats\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import datetime\n",
    "import glob\n",
    "from scipy import integrate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import ImageFile, Image\n",
    "import sys\n",
    "sys.path.insert(1, '../architecture')\n",
    "sys.path.insert(2, '../dataLoaders')\n",
    "from ProUNet import *\n",
    "import torchvision.models as models\n",
    "from MapillaryDataLoader import *\n",
    "from volvoDataLoader_onFly import *\n",
    "from VolvoDataLoader import *\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "#from MapRSCD import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapil_tr = MapRSCD(datasetRootPath = '../../../datasets/augmented_mapillary', mapillaryConfigFileAdd = \"../../../datasets/mapillary\", mode = 'train', imgSize = (256,256))\n",
    "args = {\n",
    "    \"mode\":\"train\",\n",
    "    \"input_img_dim\":(256,256),\n",
    "    \"mapillaryRootPath\":'../../../datasets/augmented_mapillary',\n",
    "    \"cityscapesRootPath\":'../../../datasets/augmented_cityscapes',\n",
    "    \"RSCDRootPath\":'../../../datasets/RSCD',\n",
    "    \"volvoRootPath\":\"../../../datasets/VolvoAnnotatedImages/rawDataset/images\",\n",
    "    \"reducedCategories\":True\n",
    "}\n",
    "\n",
    "dataloader = volvo_onFly(**args)\n",
    "\n",
    "# dataloader = mapillaryDataLoader(**{\"mapillaryRootPath\":'../../../datasets/augmented_mapillary', \"mode\":\"train\", \"input_img_dim\": (256,256), \"reducedCategories\":{\"enable\":True}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858580f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "model = ProUNet(gecoConfig = {\"enable\":False}, device = device, num_classes = dataloader.get_num_classes(), LatentVarSize = 6, beta = 3, training = True, num_samples = 16).to(device)\n",
    "check = torch.load(\"../checkpoints/HVAEFri_volvo_onTheFly_crf3/best.pth\", map_location=device)\n",
    "model.load_state_dict(check['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc384053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy_distance_components(gt_seg_modes, seg_samples, eval_class_ids, ignore_mask=None):\n",
    "    \"\"\"\n",
    "    Calculates the components for the IoU-based generalized energy distance given an array holding all segmentation\n",
    "    modes and an array holding all sampled segmentations.\n",
    "    :param gt_seg_modes: N-D array in format (num_modes,[...],H,W)\n",
    "    :param seg_samples: N-D array in format (num_samples,[...],H,W)\n",
    "    :param eval_class_ids: integer or list of integers specifying the classes to encode, if integer range() is applied\n",
    "    :param ignore_mask: N-D array in format ([...],H,W)\n",
    "    :return: dict\n",
    "    \"\"\"\n",
    "    num_modes = gt_seg_modes.shape[0]\n",
    "    num_samples = seg_samples.shape[0]\n",
    "\n",
    "    if isinstance(eval_class_ids, int):\n",
    "        eval_class_ids = list(range(eval_class_ids))\n",
    "\n",
    "    d_matrix_YS = np.zeros(shape=(num_modes, num_samples, len(eval_class_ids)), dtype=np.float32)\n",
    "    d_matrix_YY = np.zeros(shape=(num_modes, num_modes, len(eval_class_ids)), dtype=np.float32)\n",
    "    d_matrix_SS = np.zeros(shape=(num_samples, num_samples, len(eval_class_ids)), dtype=np.float32)\n",
    "\n",
    "    # iterate all ground-truth modes\n",
    "    for mode in range(num_modes):\n",
    "\n",
    "        ##########################################\n",
    "        #   Calculate d(Y,S) = [1 - IoU(Y,S)],\t #\n",
    "        #   with S ~ P_pred, Y ~ P_gt  \t\t\t #\n",
    "        ##########################################\n",
    "\n",
    "        # iterate the samples S\n",
    "        for i in range(num_samples):\n",
    "            conf_matrix = training_utils.calc_confusion(gt_seg_modes[mode], seg_samples[i],\n",
    "                                                        loss_mask=ignore_mask, class_ixs=eval_class_ids)\n",
    "            iou = training_utils.metrics_from_conf_matrix(conf_matrix)['iou']\n",
    "            d_matrix_YS[mode, i] = 1. - iou\n",
    "\n",
    "        ###########################################\n",
    "        #   Calculate d(Y,Y') = [1 - IoU(Y,Y')],  #\n",
    "        #   with Y,Y' ~ P_gt  \t   \t\t\t\t  #\n",
    "        ###########################################\n",
    "\n",
    "        # iterate the ground-truth modes Y' while exploiting the pair-wise symmetries for efficiency\n",
    "        for mode_2 in range(mode, num_modes):\n",
    "            conf_matrix = training_utils.calc_confusion(gt_seg_modes[mode], gt_seg_modes[mode_2],\n",
    "                                                        loss_mask=ignore_mask, class_ixs=eval_class_ids)\n",
    "            iou = training_utils.metrics_from_conf_matrix(conf_matrix)['iou']\n",
    "            d_matrix_YY[mode, mode_2] = 1. - iou\n",
    "            d_matrix_YY[mode_2, mode] = 1. - iou\n",
    "\n",
    "    #########################################\n",
    "    #   Calculate d(S,S') = 1 - IoU(S,S'),  #\n",
    "    #   with S,S' ~ P_pred        \t\t\t#\n",
    "    #########################################\n",
    "\n",
    "    # iterate all samples S\n",
    "    for i in range(num_samples):\n",
    "        # iterate all samples S'\n",
    "        for j in range(i, num_samples):\n",
    "            conf_matrix = training_utils.calc_confusion(seg_samples[i], seg_samples[j],\n",
    "                                                        loss_mask=ignore_mask, class_ixs=eval_class_ids)\n",
    "            iou = training_utils.metrics_from_conf_matrix(conf_matrix)['iou']\n",
    "            d_matrix_SS[i, j] = 1. - iou\n",
    "            d_matrix_SS[j, i] = 1. - iou\n",
    "\n",
    "    return {'YS': d_matrix_YS, 'SS': d_matrix_SS, 'YY': d_matrix_YY}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819a0f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d15901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8db7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d053b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f89934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc564264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feea354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84660f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61fb07a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6851ba42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17982008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad93eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8",
   "language": "python",
   "name": "3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
